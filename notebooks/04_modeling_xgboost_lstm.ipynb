{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ea7741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded: (6435, 21)\n",
      "   Store       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1 2010-02-05      1.074309             0    -0.995136   -1.713800   \n",
      "1      1 2010-02-12      1.071198             1    -1.201170   -1.766089   \n",
      "2      1 2010-02-19      1.017382             0    -1.124178   -1.840166   \n",
      "3      1 2010-02-26      0.654458             0    -0.760907   -1.737766   \n",
      "4      1 2010-03-05      0.914805             0    -0.767955   -1.598328   \n",
      "\n",
      "        CPI  Unemployment  Dept  Year  ...  Week  Day  day_of_week  \\\n",
      "0  1.004175      0.056964     1  2010  ...     5    5            4   \n",
      "1  1.007880      0.056964     1  2010  ...     6   12            4   \n",
      "2  1.009074      0.056964     1  2010  ...     7   19            4   \n",
      "3  1.009849      0.056964     1  2010  ...     8   26            4   \n",
      "4  1.010624      0.056964     1  2010  ...     9    5            4   \n",
      "\n",
      "   is_weekend  sales_lag_1  sales_lag_2  sales_lag_4  rolling_mean_4w  \\\n",
      "0           0    -1.845796    -1.817103    -1.762558        -1.819329   \n",
      "1           0     1.077190    -1.817103    -1.762558        -1.819329   \n",
      "2           0     1.074107     1.080017    -1.762558        -1.819329   \n",
      "3           0     1.020777     1.076961    -1.762558        -1.819329   \n",
      "4           0     0.661131     1.024103     1.087854         0.985289   \n",
      "\n",
      "   rolling_mean_12w  rolling_std_4w  \n",
      "0         -1.633434       -0.802314  \n",
      "1         -1.633434       -0.802314  \n",
      "2         -1.633434       -0.802314  \n",
      "3         -1.633434       -0.802314  \n",
      "4         -1.633434        0.414806  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Features (X) head:\n",
      "  Store  Holiday_Flag  Temperature  Fuel_Price       CPI  Unemployment Dept  \\\n",
      "0     1             0    -0.995136   -1.713800  1.004175      0.056964    1   \n",
      "1     1             1    -1.201170   -1.766089  1.007880      0.056964    1   \n",
      "2     1             0    -1.124178   -1.840166  1.009074      0.056964    1   \n",
      "3     1             0    -0.760907   -1.737766  1.009849      0.056964    1   \n",
      "4     1             0    -0.767955   -1.598328  1.010624      0.056964    1   \n",
      "\n",
      "   Year  Month  Week  Day  day_of_week  is_weekend  sales_lag_1  sales_lag_2  \\\n",
      "0  2010      2     5    5            4           0    -1.845796    -1.817103   \n",
      "1  2010      2     6   12            4           0     1.077190    -1.817103   \n",
      "2  2010      2     7   19            4           0     1.074107     1.080017   \n",
      "3  2010      2     8   26            4           0     1.020777     1.076961   \n",
      "4  2010      3     9    5            4           0     0.661131     1.024103   \n",
      "\n",
      "   sales_lag_4  rolling_mean_4w  rolling_mean_12w  rolling_std_4w  \n",
      "0    -1.762558        -1.819329         -1.633434       -0.802314  \n",
      "1    -1.762558        -1.819329         -1.633434       -0.802314  \n",
      "2    -1.762558        -1.819329         -1.633434       -0.802314  \n",
      "3    -1.762558        -1.819329         -1.633434       -0.802314  \n",
      "4     1.087854         0.985289         -1.633434        0.414806  \n",
      "\n",
      "Target (y) head:\n",
      "0    1.074309\n",
      "1    1.071198\n",
      "2    1.017382\n",
      "3    0.654458\n",
      "4    0.914805\n",
      "Name: Weekly_Sales, dtype: float64\n",
      "\n",
      "Training set: (5148, 19) Testing set: (1287, 19)\n",
      "\n",
      "Categorical columns identified: []\n",
      "Numerical columns identified: ['Store', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Dept', 'Year', 'Month', 'Week', 'Day', 'day_of_week', 'is_weekend', 'sales_lag_1', 'sales_lag_2', 'sales_lag_4', 'rolling_mean_4w', 'rolling_mean_12w', 'rolling_std_4w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FR4001TU\\AppData\\Local\\Temp\\ipykernel_10852\\1538981937.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
      "C:\\Users\\FR4001TU\\AppData\\Local\\Temp\\ipykernel_10852\\1538981937.py:47: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training complete. Used 19 numeric and 0 categorical features.\n",
      "‚úÖ Predictions shape: (1287,)\n",
      "\n",
      "üìä Model Evaluation\n",
      "MAE : 0.09\n",
      "RMSE: 0.14\n",
      "R¬≤  : 0.9795\n",
      "üíæ Saved pipeline to: ../models/rf_sales_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# ## 04_model_training.ipynb (Without XGBoost)\n",
    "\n",
    "# ### 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "# ### 2. Load Data\n",
    "features_path = \"../data/processed/walmart_with_features.csv\"\n",
    "df = pd.read_csv(features_path, parse_dates=['Date'])\n",
    "\n",
    "print(\"‚úÖ Data Loaded:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "if 'Dept' not in df.columns:\n",
    "    df['Dept'] = 1\n",
    "    print(\"\\n‚ö†Ô∏è 'Dept' column not found in data. A dummy column has been created for training.\")\n",
    "\n",
    "# ### 3. Prepare Data: Define Features and Target, and handle data types\n",
    "df['Store'] = df['Store'].astype(object)\n",
    "df['Dept'] = df['Dept'].astype(object)\n",
    "\n",
    "X = df.drop(columns=[\"Weekly_Sales\", \"Date\"])\n",
    "y = df[\"Weekly_Sales\"]\n",
    "\n",
    "print(\"\\nFeatures (X) head:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget (y) head:\")\n",
    "print(y.head())\n",
    "\n",
    "# ### 4. Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"\\nTraining set:\", X_train.shape, \"Testing set:\", X_test.shape)\n",
    "\n",
    "# ### 5. Train Robust Random Forest Pipeline\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "if hasattr(y_train, \"isna\"):\n",
    "    _mask = ~y_train.isna()\n",
    "    X_train = X_train.loc[_mask]\n",
    "    y_train = y_train.loc[_mask]\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns identified: {cat_cols}\")\n",
    "print(f\"Numerical columns identified: {num_cols}\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"enc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[(\"prep\", preprocess), (\"rf\", rf_model)])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"\\n‚úÖ Training complete. Used {len(num_cols)} numeric and {len(cat_cols)} categorical features.\")\n",
    "\n",
    "# ### 6. Predictions (pipeline-safe)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"‚úÖ Predictions shape:\", y_pred.shape)\n",
    "\n",
    "# ### 7. Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nüìä Model Evaluation\")\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R¬≤  : {r2:.4f}\")\n",
    "\n",
    "# ### 8. Save Pipeline\n",
    "save_path = \"../models/rf_sales_pipeline.pkl\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "joblib.dump(model, save_path)\n",
    "print(f\"üíæ Saved pipeline to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67fb0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features (X) head:\n",
      "  Store  Holiday_Flag  Temperature  Fuel_Price       CPI  Unemployment  year  \\\n",
      "0     1             0    -0.767955   -1.598328  1.010624      0.056964  2010   \n",
      "1     1             0    -0.155815   -1.506821  1.011399      0.056964  2010   \n",
      "2     1             0    -0.329861   -1.391349  1.007206      0.056964  2010   \n",
      "3     1             0    -0.499568   -1.365204  1.002185      0.056964  2010   \n",
      "4     1             0     0.087089   -1.393527  0.997164     -0.101907  2010   \n",
      "\n",
      "   month  week  day_of_week  is_weekend  sales_lag_1  sales_lag_2  \\\n",
      "0      3     9            4           0     0.654458     1.017382   \n",
      "1      3    10            4           0     0.914805     0.654458   \n",
      "2      3    11            4           0     0.707959     0.914805   \n",
      "3      3    12            4           0     0.767132     0.707959   \n",
      "4      4    13            4           0     0.644951     0.767132   \n",
      "\n",
      "   sales_lag_4  rolling_mean_4w  rolling_std_4w Dept  \n",
      "0     1.074309         0.954337        0.201620    1  \n",
      "1     1.071198         0.914461        0.185078    1  \n",
      "2     1.017382         0.823651        0.171125    1  \n",
      "3     0.654458         0.761088        0.112336    1  \n",
      "4     0.914805         0.758712        0.115403    1  \n",
      "\n",
      "Target (y) head:\n",
      "0    0.914805\n",
      "1    0.707959\n",
      "2    0.767132\n",
      "3    0.644951\n",
      "4    0.986875\n",
      "Name: Weekly_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- NEW ADDITION TO HANDLE MISSING DEPT COLUMN ---\n",
    "if 'Dept' not in df.columns:\n",
    "    df['Dept'] = 1\n",
    "    print(\"\\n 'Dept' column not found in data. A dummy column has been created for training.\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# ### 3. Prepare Data: Define Features and Target, and handle data types\n",
    "df['Store'] = df['Store'].astype(object)\n",
    "df['Dept'] = df['Dept'].astype(object)\n",
    "\n",
    "X = df.drop(columns=[\"Weekly_Sales\", \"Date\"])\n",
    "y = df[\"Weekly_Sales\"]\n",
    "\n",
    "print(\"\\nFeatures (X) head:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget (y) head:\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00c02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features (X) head:\n",
      "  Store  Holiday_Flag  Temperature  Fuel_Price       CPI  Unemployment  year  \\\n",
      "0     1             0    -0.767955   -1.598328  1.010624      0.056964  2010   \n",
      "1     1             0    -0.155815   -1.506821  1.011399      0.056964  2010   \n",
      "2     1             0    -0.329861   -1.391349  1.007206      0.056964  2010   \n",
      "3     1             0    -0.499568   -1.365204  1.002185      0.056964  2010   \n",
      "4     1             0     0.087089   -1.393527  0.997164     -0.101907  2010   \n",
      "\n",
      "   month  week  day_of_week  is_weekend  sales_lag_1  sales_lag_2  \\\n",
      "0      3     9            4           0     0.654458     1.017382   \n",
      "1      3    10            4           0     0.914805     0.654458   \n",
      "2      3    11            4           0     0.707959     0.914805   \n",
      "3      3    12            4           0     0.767132     0.707959   \n",
      "4      4    13            4           0     0.644951     0.767132   \n",
      "\n",
      "   sales_lag_4  rolling_mean_4w  rolling_std_4w Dept  \n",
      "0     1.074309         0.954337        0.201620    1  \n",
      "1     1.071198         0.914461        0.185078    1  \n",
      "2     1.017382         0.823651        0.171125    1  \n",
      "3     0.654458         0.761088        0.112336    1  \n",
      "4     0.914805         0.758712        0.115403    1  \n",
      "\n",
      "Target (y) head:\n",
      "0    0.914805\n",
      "1    0.707959\n",
      "2    0.767132\n",
      "3    0.644951\n",
      "4    0.986875\n",
      "Name: Weekly_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    " ### 3. Prepare Data: Define Features and Target, and handle data types\n",
    "# Convert 'Store' and 'Dept' to object type if they are numeric,\n",
    "# so they are correctly identified as categorical by the ColumnTransformer.\n",
    "# This ensures consistency for OrdinalEncoder.\n",
    "df['Store'] = df['Store'].astype(object)\n",
    "df['Dept'] = df['Dept'].astype(object)\n",
    "\n",
    "# Drop the 'Date' column as its components (Year, Month, etc.) are already features.\n",
    "# 'Weekly_Sales' is the target.\n",
    "X = df.drop(columns=[\"Weekly_Sales\", \"Date\"])\n",
    "y = df[\"Weekly_Sales\"]\n",
    "\n",
    "print(\"\\nFeatures (X) head:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget (y) head:\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c79c2bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (5004, 17) Testing set: (1251, 17)\n"
     ]
    }
   ],
   "source": [
    "# ### 4. Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Training set:\", X_train.shape, \"Testing set:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a64963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FR4001TU\\AppData\\Local\\Temp\\ipykernel_7496\\2947779803.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
      "C:\\Users\\FR4001TU\\AppData\\Local\\Temp\\ipykernel_7496\\2947779803.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns identified: []\n",
      "Numerical columns identified: ['Store', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'year', 'month', 'week', 'day_of_week', 'is_weekend', 'sales_lag_1', 'sales_lag_2', 'sales_lag_4', 'rolling_mean_4w', 'rolling_std_4w', 'Dept']\n",
      "\n",
      " Training complete. Used 17 numeric and 0 categorical features.\n"
     ]
    }
   ],
   "source": [
    " ### 5. Train Robust Random Forest Pipeline\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "if hasattr(y_train, \"isna\"):\n",
    "    _mask = ~y_train.isna()\n",
    "    X_train = X_train.loc[_mask]\n",
    "    y_train = y_train.loc[_mask]\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns identified: {cat_cols}\")\n",
    "print(f\"Numerical columns identified: {num_cols}\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"enc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[(\"prep\", preprocess), (\"rf\", rf_model)])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"\\n Training complete. Used {len(num_cols)} numeric and {len(cat_cols)} categorical features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13900ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predictions shape: (1287,)\n"
     ]
    }
   ],
   "source": [
    "# ### 6. Predictions (pipeline-safe)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"‚úÖ Predictions shape:\", y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff77969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved pipeline to: ../models/rf_sales_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    " ### 8. Save Pipeline\n",
    "save_path = \"../models/rf_sales_pipeline.pkl\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "joblib.dump(model, save_path)\n",
    "print(f\" Saved pipeline to: {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "097ee383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved pipeline to: ../models/rf_sales_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# ### 8. Save Pipeline\n",
    "import os, joblib\n",
    "\n",
    "save_path = \"../models/rf_sales_pipeline.pkl\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "joblib.dump(model, save_path)\n",
    "print(f\" Saved pipeline to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17ec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
